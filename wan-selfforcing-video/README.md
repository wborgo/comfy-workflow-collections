# Workflow: Wan Self Forcing + VACE

Este workflow usa o modelo derivado do Wan2.1 com a tÃ©cnica **Self Forcing**, integrado ao pipeline de geraÃ§Ã£o de vÃ­deo **VACE (Video Autoencoding via Composition and Editing)**.

O foco aqui Ã© performance: geraÃ§Ã£o de vÃ­deos curtos com alta qualidade visual, mesmo em setups locais modestos.

---

## âš™ï¸ Requisitos

- **GPU**: RTX 3060 (mÃ­nimo 12GB VRAM)
- **RAM**: 16GB
- [ComfyUI instalado](https://github.com/comfyanonymous/ComfyUI)
- Modelos necessÃ¡rios:
  - `wan-sf-1.3b` (modelo Self Forcing)
  - Depth detector (Canny / OpenPose / Midas, etc.)
  - Background remover (ex: MODNet)
  - Modelo LoRA (opcional)

---

## â–¶ï¸ Como usar

1. Carregue o `workflow.json` no ComfyUI.
2. Insira:
   - Um **vÃ­deo de referÃªncia** (animaÃ§Ã£o/movimento)
   - Uma **imagem de referÃªncia** (personagem, rosto, etc.)
3. (Opcional) Aplique LoRAs para adicionar estilo artÃ­stico.
4. Execute o pipeline.

---

## ğŸ“Œ Detalhes tÃ©cnicos

- ResoluÃ§Ã£o atual: **480p**
- DuraÃ§Ã£o: atÃ© **5 segundos**
- Frame rate: **16fps**
- Tempo mÃ©dio de geraÃ§Ã£o: **~2 minutos** em hardware modesto

---

## ğŸ¨ PersonalizaÃ§Ã£o

- Altere o mÃ©todo de Depth Map conforme sua preferÃªncia.
- Troque a imagem de referÃªncia para diferentes personagens.
- Aplique LoRAs para adicionar estilo ou identidade visual ao vÃ­deo.

---

## ğŸ§ª Resultado

*Adicione aqui uma imagem ou link para um exemplo gerado, se quiser mostrar o impacto visual do pipeline.*

---
